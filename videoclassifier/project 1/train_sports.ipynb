{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91914ca0-4bb7-4c92-b13d-dd20ff2ec0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b5b85b-a375-4f8e-817f-9935fe8126ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ced0c5a-922f-4393-bc00-1fae795f48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d45e11-434b-40e3-b2d6-88626f14f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4bd372-3ebf-46c8-976d-6b203e9da7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"C:/Users/Dell/Desktop/videoclassifier/data\"\n",
    "outputmodel = \"C:/Users/Dell/Desktop/videoclassifier/video_classification_model/videoClassificationModel.keras\"\n",
    "outputlabelbinarizer = \"C:/Users/Dell/Desktop/videoclassifier/model/videoClassificationBinarizer\"\n",
    "epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780ef7de-ff76-42bf-beb6-7a90a7ca1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are being loaded...\n"
     ]
    }
   ],
   "source": [
    "Sports_Labels = set(['boxing', 'swimming','table_tennis'])\n",
    "print(\"Images are being loaded...\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in Sports_Labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image,(244,244))\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2401b9-e045-41af-9c93-20088c24223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "#hot encoded values as 0,1,2\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec706198-425a-4246-8f4d-e485a04d694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d4127f-346e-4192-8047-cee8292b4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean values for normalization\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "\n",
    "# Define a function to normalize images\n",
    "def preprocess_image(img):\n",
    "    return img - mean\n",
    "\n",
    "# Initialize ImageDataGenerator for training with augmentations\n",
    "traininAugmentation = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_image  # Apply normalization\n",
    ")\n",
    "\n",
    "# Initialize ImageDataGenerator for validation without augmentations\n",
    "validationAugmentation = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image  # Apply normalization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce74ad97-4d38-449b-a652-f4817c582c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2ad21f-a54d-4cba-9ae6-9a18a3e7bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top= False, input_tensor=Input(shape=(244,244,3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for basemodelLayers in baseModel.layers:\n",
    "    basemodelLayers.trainabble = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f52436-8f45-4838-a859-792a12e7da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48515da-eb8a-44f5-a079-fb3cc9572edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(learning_rate=0.0001, momentum=0.9, decay=1e-4/epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "025a8289-b011-420a-afd8-3c09712371c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "036ff3da-00ba-4a9c-b701-cde2d47f1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 13s/step - accuracy: 0.3928 - loss: 1.3790 - val_accuracy: 0.8086 - val_loss: 0.5351\n",
      "Epoch 2/25\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:16\u001b[0m 12s/step - accuracy: 0.6562 - loss: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.6562 - loss: 0.8750 - val_accuracy: 0.9091 - val_loss: 0.4293\n",
      "Epoch 3/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 13s/step - accuracy: 0.6987 - loss: 0.7156 - val_accuracy: 0.9062 - val_loss: 0.3007\n",
      "Epoch 4/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.3979 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 5/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2519s\u001b[0m 52s/step - accuracy: 0.8127 - loss: 0.5000 - val_accuracy: 0.9316 - val_loss: 0.2165\n",
      "Epoch 6/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - accuracy: 0.8438 - loss: 0.4264 - val_accuracy: 0.9091 - val_loss: 0.2577\n",
      "Epoch 7/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 13s/step - accuracy: 0.8600 - loss: 0.3888 - val_accuracy: 0.9277 - val_loss: 0.1917\n",
      "Epoch 8/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.3574 - val_accuracy: 0.8182 - val_loss: 0.4402\n",
      "Epoch 9/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 14s/step - accuracy: 0.8847 - loss: 0.3045 - val_accuracy: 0.9473 - val_loss: 0.1586\n",
      "Epoch 10/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.2625 - val_accuracy: 1.0000 - val_loss: 0.1488\n",
      "Epoch 11/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 13s/step - accuracy: 0.9013 - loss: 0.2970 - val_accuracy: 0.9551 - val_loss: 0.1472\n",
      "Epoch 12/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2471 - val_accuracy: 1.0000 - val_loss: 0.0475\n",
      "Epoch 13/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 12s/step - accuracy: 0.9108 - loss: 0.2330 - val_accuracy: 0.9551 - val_loss: 0.1384\n",
      "Epoch 14/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.8750 - loss: 0.1991 - val_accuracy: 1.0000 - val_loss: 0.0258\n",
      "Epoch 15/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m590s\u001b[0m 12s/step - accuracy: 0.9109 - loss: 0.2463 - val_accuracy: 0.9570 - val_loss: 0.1229\n",
      "Epoch 16/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.3744 - val_accuracy: 0.9091 - val_loss: 0.2486\n",
      "Epoch 17/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 11s/step - accuracy: 0.9371 - loss: 0.2072 - val_accuracy: 0.9570 - val_loss: 0.1134\n",
      "Epoch 18/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9688 - loss: 0.0994 - val_accuracy: 1.0000 - val_loss: 0.1050\n",
      "Epoch 19/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 9s/step - accuracy: 0.9316 - loss: 0.1934 - val_accuracy: 0.9590 - val_loss: 0.1082\n",
      "Epoch 20/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.1855 - val_accuracy: 1.0000 - val_loss: 0.0390\n",
      "Epoch 21/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 10s/step - accuracy: 0.9331 - loss: 0.1732 - val_accuracy: 0.9648 - val_loss: 0.0973\n",
      "Epoch 22/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9688 - loss: 0.1148 - val_accuracy: 0.9091 - val_loss: 0.1194\n",
      "Epoch 23/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 9s/step - accuracy: 0.9406 - loss: 0.1749 - val_accuracy: 0.9590 - val_loss: 0.0951\n",
      "Epoch 24/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9375 - loss: 0.1651 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
      "Epoch 25/25\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 9s/step - accuracy: 0.9535 - loss: 0.1397 - val_accuracy: 0.9629 - val_loss: 0.0891\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(\n",
    "    traininAugmentation.flow(X_train, Y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train)//32,\n",
    "    validation_data=validationAugmentation.flow(X_test, Y_test),\n",
    "    validation_steps=len(X_test)//32,\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6071bbf4-f387-439b-9f3e-40ea96664de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8721d48d-2965-4500-92fd-46234f347d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: C:/Users/Dell/Desktop/videoclassifier/video_classification_model/videoClassificationModel.keras\n",
      "Binarizer saved successfully at: C:/Users/Dell/Desktop/videoclassifier/video_classification_model/videoClassificationBinarizer.pickle\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.dirname(outputmodel), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "try:\n",
    "    model.save(outputmodel)\n",
    "    print(f\"Model saved successfully at: {outputmodel}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "\n",
    "# Define the path for the label binarizer\n",
    "binarizer_path = r\"C:/Users/Dell/Desktop/videoclassifier/video_classification_model/videoClassificationBinarizer.pickle\"\n",
    "\n",
    "# Create the directory for the binarizer if it doesn't exist\n",
    "os.makedirs(os.path.dirname(binarizer_path), exist_ok=True)\n",
    "\n",
    "# Save the label binarizer\n",
    "try:\n",
    "    with open(binarizer_path, \"wb\") as lbinarizer:\n",
    "        pickle.dump(lb, lbinarizer)\n",
    "        print(f\"Binarizer saved successfully at: {binarizer_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving binarizer: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec18377-c92c-4f78-88b2-0a647ebfa90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
